{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q git+https://github.com/matjesg/deepflash2.git\n!pip install segmentation_models_pytorch\n!pip install pytorch-lightning\n!pip install neptune-client","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zarr, cv2\nfrom fastai.vision.all import *\nfrom fastai.data.transforms import Normalize as N\nfrom deepflash2.all import *\nimport albumentations as alb\n\nimport torch\nfrom torch import nn\nimport torchvision\nimport os\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage.interpolation import zoom\nfrom albumentations import *\nfrom torch.nn import functional as F\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport tifffile as tiff\nimport cv2\nimport zipfile\nimport time\nimport random\nimport segmentation_models_pytorch as smp\nfrom segmentation_models_pytorch.unet import Unet\nfrom segmentation_models_pytorch import Linknet\nfrom tqdm.notebook import tqdm\nfrom torchmetrics import Metric\n\nimport pytorch_lightning as pl\n\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\nfrom pytorch_lightning.loggers.neptune import NeptuneLogger\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@patch\ndef read_img(self:BaseDataset, file, *args, **kwargs):\n    return zarr.open(str(file), mode='r')\n\n@patch\ndef _name_fn(self:BaseDataset, g):\n    \"Name of preprocessed and compressed data.\"\n    return f'{g}'\n\n@patch\ndef apply(self:DeformationField, data, offset=(0, 0), pad=(0, 0), order=1):\n    \"Apply deformation field to image using interpolation\"\n    outshape = tuple(int(s - p) for (s, p) in zip(self.shape, pad))\n    coords = [np.squeeze(d).astype('float32').reshape(*outshape) for d in self.get(offset, pad)]\n    # Get slices to avoid loading all data (.zarr files)\n    sl = []\n    for i in range(len(coords)):\n        cmin, cmax = int(coords[i].min()), int(coords[i].max())\n        dmax = data.shape[i]\n        if cmin<0: \n            cmax = max(-cmin, cmax)\n            cmin = 0 \n        elif cmax>dmax:\n            cmin = min(cmin, 2*dmax-cmax)\n            cmax = dmax\n            coords[i] -= cmin\n        else: coords[i] -= cmin\n        sl.append(slice(cmin, cmax))    \n    if len(data.shape) == len(self.shape) + 1:\n        tile = np.empty((*outshape, data.shape[-1]))\n        for c in range(data.shape[-1]):\n            # Adding divide\n            tile[..., c] = cv2.remap(data[sl[0],sl[1], c]/255, coords[1],coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT)\n    else:\n        tile = cv2.remap(data[sl[0], sl[1]], coords[1], coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT)\n    return tile","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG():\n    \n    # data paths\n    data_path = Path('../input/hubmap-kidney-segmentation')\n    data_path_zarr = Path('../input/hubmap-zarr-dataset/train_scale2')\n    mask_preproc_dir = '../input/hubmap-labels/masks_scale2'\n    \n    # deepflash2 dataset\n    scale = 1 # data is already downscaled to 2, so absulute downscale is 3\n    tile_shape = (512, 512)\n    padding = (0,0) # Border overlap for prediction\n    n_jobs = 1\n    sample_mult = 100 # Sample 100 tiles from each image, per epoch\n    val_length = 500 # Randomly sample 500 validation tiles\n    stats = np.array([0.61561477, 0.5179343 , 0.64067212]), np.array([0.2915353 , 0.31549066, 0.28647661])\n    \n    # deepflash2 augmentation options\n    zoom_sigma = 0.1\n    flip = True\n    max_rotation = 360\n    deformation_grid_size = (150,150)\n    deformation_magnitude = (10,10)\n    \n\n    # pytorch model (segmentation_models_pytorch)\n    encoder_name = \"efficientnet-b4\"\n    encoder_weights = 'imagenet'\n    in_channels = 3\n    classes = 2\n    \n    # Lightning Learner\n    batch_size = 8\n    epochs = 50\n    learning_rate = 1e-3\n    decay = 0.01\n    virtual_batch_size = 32\n    \n    # fastai Learner \n    mixed_precision_training = True\n    weight_decay = 0.01\n    loss_func = CrossEntropyLossFlat(axis=1)\n    metrics = [Iou(), Dice_f1()]\n    optimizer = ranger\n    max_learning_rate = 1e-4\n    epochs = 12\n    \ncfg = CONFIG()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfms = alb.OneOf([\n    alb.HueSaturationValue(10,15,10),\n    alb.CLAHE(clip_limit=2),\n    alb.RandomBrightnessContrast(),            \n    ], p=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(cfg.data_path/'train.csv')\ndf_info = pd.read_csv(cfg.data_path/'HuBMAP-20-dataset_information.csv')\n\nfiles = [x for x in cfg.data_path_zarr.iterdir() if x.is_dir() if not x.name.startswith('.')]\nlabel_fn = lambda o: o","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Datasets\nds_kwargs = {\n    'tile_shape':cfg.tile_shape,\n    'padding':cfg.padding,\n    'scale': cfg.scale,\n    'n_jobs': cfg.n_jobs, \n    'preproc_dir': cfg.mask_preproc_dir, \n    'val_length':cfg.val_length, \n    'sample_mult':cfg.sample_mult,\n    'loss_weights':False,\n    'zoom_sigma': cfg.zoom_sigma,\n    'flip' : cfg.flip,\n    'max_rotation': cfg.max_rotation,\n    'deformation_grid_size' : cfg.deformation_grid_size,\n    'deformation_magnitude' : cfg.deformation_magnitude,\n    'albumentations_tfms': tfms\n}\n\ntrain_ds = RandomTileDataset(files, label_fn=label_fn, **ds_kwargs)\nvalid_ds = TileDataset(files, label_fn=label_fn, **ds_kwargs, is_zarr=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls = DataLoaders.from_dsets(train_ds,\n                            valid_ds,\n                            bs=cfg.batch_size, \n                            after_batch = N.from_stats(*cfg.stats))\n\ndls = dls.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HuBMAP(nn.Module):\n    def __init__(self):\n        super(HuBMAP, self).__init__()\n        self.cnn_model = Unet(cfg.encoder_name, encoder_weights=cfg.encoder_weights, in_channels=cfg.in_channels,classes=cfg.classes, activation=None)\n        #self.cnn_model.decoder.blocks.append(self.cnn_model.decoder.blocks[-1])\n        #self.cnn_model.decoder.blocks[-2] = self.cnn_model.decoder.blocks[-3]\n    \n    def forward(self, imgs):\n        img_segs = self.cnn_model(imgs)\n        return img_segs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#losses\n\nclass BCEMultiClass(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(BCEMultiClass, self).__init__()\n        self.loss_func = nn.BCEWithLogitsLoss()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        bs = inputs.size(0)\n        \n#         inputs = inputs.log_softmax(dim=1).exp()       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(bs, cfg.classes, -1)\n        targets = targets.view(bs, -1)\n        targets = F.one_hot(targets, 2).permute(0,2,1)\n        \n        loss = self.loss_func(torch.tensor(inputs).clone().detach().requires_grad_(True), torch.tensor(targets).type_as(inputs).clone().detach().requires_grad_(True))\n        \n        return loss\n\nclass LogCosHDice(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(LogCosHDice, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        bs = inputs.size(0)\n        \n        inputs = inputs.log_softmax(dim=1).exp()       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(bs, cfg.classes, -1)\n        targets = targets.view(bs, -1)\n        targets = F.one_hot(targets, 2).permute(0,2,1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n        \n        return torch.log(torch.cosh(1 - dice))\n    \nclass DiceLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        bs = inputs.size(0)\n        \n        inputs = inputs.log_softmax(dim=1).exp()       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(bs, cfg.classes, -1)\n        targets = targets.view(bs, -1)\n        targets = F.one_hot(targets, 2).permute(0,2,1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n        \n        return (1 - dice)\n    \nclass CELogCosHDice(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(CELogCosHDice, self).__init__()\n        \n        self.ce = CrossEntropyLossFlat(axis = 1)\n        self.lcd = LogCosHDice()\n\n    def forward(self, inputs, targets):\n        \n        l1 = self.ce(inputs, targets) \n        l2 = self.lcd(inputs, targets)\n        \n        return l1+l2\n        \n    \nclass CEDiceLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(CEDiceLoss, self).__init__()\n        self.ce = CrossEntropyLossFlat(axis = 1)\n        self.d = DiceLoss()\n\n    def forward(self, inputs, targets):\n        \n        l1 = self.ce(inputs, targets)\n        l2 = self.d(inputs, targets)\n        \n        return l1 + l2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiceCoeff(Metric):\n    def __init__(self, dist_sync_on_step=False, eps = 1e-7):\n        super().__init__(dist_sync_on_step=dist_sync_on_step)\n        \n        self.eps = eps\n\n        self.add_state(\"inter\", default=torch.tensor(0, dtype = torch.float32), dist_reduce_fx=\"sum\")\n        self.add_state(\"union\", default=torch.tensor(0, dtype = torch.float32), dist_reduce_fx=\"sum\")\n\n    def update(self, preds: torch.Tensor, target: torch.Tensor):\n        bs = preds.size(0)\n        preds, target = preds.argmax(dim=1).view(-1), target.view(-1)\n        assert preds.shape == target.shape, f\"Expected output and target to have the same number of elements but got {len(preds)} and {len(target)}.\"\n\n        self.inter += (preds*target).float().sum().item()\n        self.union += (preds+target).float().sum().item()\n\n    def compute(self):\n        return (2.0 * self.inter)/(self.union + 1e-7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#losses single class\nclass BCELoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(BCELoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        BCE = F.binary_cross_entropy_with_logits(inputs, targets, reduction='mean')\n        \n        return BCE\n    \n#metric single class\nclass DiceCoeffS(Metric):\n    def __init__(self, dist_sync_on_step=False):\n        super().__init__(dist_sync_on_step=dist_sync_on_step)\n\n        self.add_state(\"inter\", default=torch.tensor(0, dtype = torch.float32), dist_reduce_fx=\"sum\")\n        self.add_state(\"union\", default=torch.tensor(0, dtype = torch.float32), dist_reduce_fx=\"sum\")\n\n    def update(self, preds: torch.Tensor, target: torch.Tensor):\n        preds, target = torch.sigmoid(preds).contiguous().view(-1), target.contiguous().view(-1)\n        assert preds.shape == target.shape, f\"Expected output and target to have the same number of elements but got {len(preds)} and {len(target)}.\"\n\n        self.inter += (preds*target).float().sum().item()\n        self.union += (preds+target).float().sum().item()\n\n    def compute(self):\n        return 2.0 * self.inter/self.union if self.union > 0 else None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HuBMAP_net(pl.LightningModule):\n    def __init__(self, dls, ths=np.arange(0.1,0.9,0.05), learning_rate = None, batch_size = 32, validation_batch_size = 16):\n        super().__init__()\n        #model\n        self.net = HuBMAP()\n        \n        self.dls = dls\n        \n        self.learning_rate = learning_rate\n        self.batch_size = batch_size\n        self.ths = ths\n        self.validation_batch_size = validation_batch_size\n        self.save_hyperparameters()\n\n        self.train_metric = DiceCoeff()\n        self.valid_metric = DiceCoeff()\n        \n        self.loss_function = CEDiceLoss()\n\n\n\n    def forward(self, x):\n        x = self.net(x)\n        return x\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=0.01)\n#         lr_scheduler = {\n#         \"scheduler\":torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, \n#                                                                threshold=0.001, threshold_mode='rel', cooldown=0, min_lr=1e-6, eps=1e-08, verbose = True),\n#         \"name\":\"ReduceLROnPlateau\",\n#         \"monitor\":\"Validation_loss_epoch\",\n#         \"interval\":\"epoch\"\n#         }\n    \n#         lr_scheduler = {\n#         \"scheduler\":torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=cfg.decay, last_epoch=-1, verbose=True),\n#         \"name\":\"StepLR\",\n#         }\n        \n#         lr_scheduler = {\n#         \"scheduler\":torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n#                 optimizer, T_0=5, T_mult=2, eta_min=1e-5, last_epoch=-1, verbose = True\n#             ),\n#         \"name\":\"CosineAnnealingWarmRestarts\",\n#         }\n\n        lr_scheduler = {\n        \"scheduler\":torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=  [3,15,30], gamma=0.1, last_epoch=-1, verbose=True),\n        \"name\":\"MultiStepLR\",\n        }\n        return [optimizer], [lr_scheduler]\n#         return optimizer\n\n    def training_step(self, batch, batch_idx):\n        image, targets = batch\n        y_pred = self.forward(image)\n        loss = self.loss_function(y_pred, targets)\n        train_dice_batch = self.train_metric(y_pred, targets)\n        self.log('DiceCoeff', train_dice_batch, prog_bar = True)\n        self.log('train_loss_batch', loss)\n        return {\n            'loss': loss,\n            'train_dice_batch': train_dice_batch,\n        }\n\n    def training_epoch_end(self, outputs):\n        current_train_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        train_dice_epoch = torch.stack([x['train_dice_batch'] for x in outputs]).mean()\n        self.log('Training_loss_epoch', current_train_loss)\n        self.log('Training_dice_epoch', train_dice_epoch)\n\n    def validation_step(self, batch, batch_idx):\n        image, targets = batch\n        y_pred = self.forward(image)\n        loss = self.loss_function(y_pred, targets)\n        valid_dice_batch = self.valid_metric(y_pred, targets)\n        self.log('DiceCoeff_Valid', valid_dice_batch)\n        self.log('valid_loss_batch', loss)\n        return {\n            'valid_loss': loss,\n            'valid_dice_batch': valid_dice_batch,\n        }\n\n    def validation_epoch_end(self, outputs):\n        current_val_loss = torch.stack([x['valid_loss'] for x in outputs]).mean()\n        valid_dice_epoch = torch.stack([x['valid_dice_batch'] for x in outputs]).mean()\n        print(f\"Epoch {self.current_epoch}: Dice:{valid_dice_epoch:4f}\")\n        self.log(\"Validation_loss_epoch\", current_val_loss)\n        self.log(\"Validation_dice_epoch\", valid_dice_epoch)\n        \n    def train_dataloader(self):\n        return dls.train\n      \n    def val_dataloader(self):\n        return dls.valid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n\n    neptune_logger = NeptuneLogger(\n        api_key=\"\",\n        project_name=\"\",\n        experiment_name=f\"{cfg.encoder_name}::lr={cfg.learning_rate}::lr_scheduler=CosineAnnealingWarmRestarts::CEDiceLoss\",\n        tags=[f\"{cfg.encoder_name}\"],\n    )\n\n    check_path = './lightning_checkpoints/'\n\n    checkpointer = ModelCheckpoint(\n        monitor = 'Validation_loss_epoch',\n        dirpath = check_path,\n        filename = f\"{cfg.encoder_name}\" + \"-{epoch:02d}-{Validation_loss_epoch:2f}\",\n        mode = 'min',\n        save_weights_only = True,\n        save_top_k = 1,\n        verbose = True\n    )\n\n\n    early_stopping = EarlyStopping(\n        monitor = 'Validation_loss_epoch',\n        patience = 5,\n        mode = 'min',\n        verbose = True\n    )\n\n    learning_rate_monitor = LearningRateMonitor(\n        logging_interval = 'epoch'\n    )\n\n    callbacks = [\n        checkpointer, \n        early_stopping, \n        learning_rate_monitor\n        ]\n\n    model = HuBMAP_net(dls,learning_rate=cfg.learning_rate, batch_size = cfg.batch_size, validation_batch_size = int(cfg.batch_size/2))\n    trainer = pl.Trainer(\n#         logger = neptune_logger,\n#         callbacks = callbacks,\n#         max_epochs = cfg.epochs,\n      max_epochs = 5, #for test run\n        progress_bar_refresh_rate = 20,\n        gpus = 1,\n        accumulate_grad_batches=int(cfg.virtual_batch_size/cfg.batch_size),\n        precision = 16,\n        move_metrics_to_cpu = True\n    )\n\n    trainer.fit(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}